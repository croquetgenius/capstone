{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = 'άέήίαβγδεζηθικλμνξοπρςστυφχψωόύώἀἁἂἃἄἅἆἐἑἓἔἕἠἡἢἣἤἥἦἧἰἱἳἴἵἶἷὀὁὂὃὄὅὐὑὓὔὕὖὗὠὡὢὣὤὥὦὧὰὲὴὶὸὺὼᾄᾐᾑᾔᾖᾗᾠᾤᾦᾧᾳᾴᾶᾷῂῃῄῆῇῖῥῦῳῴῶῷ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cltk.corpus.swadesh import Swadesh\n",
    "from cltk.stop.greek.stops import STOPS_LIST\n",
    "from cltk.corpus.readers import get_corpus_reader\n",
    "from cltk.tag.pos import POSTag\n",
    "from greek_accentuation.syllabify import syllabify\n",
    "import pandas as pd\n",
    "import os\n",
    "from betacode import conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_data(path:str, authors=None, swadesh=False):\n",
    "    \n",
    "    # get the greek files from path which match the author's name\n",
    "    fileids = []\n",
    "    if authors != None:\n",
    "        for root, dirs, files in os.walk(path):\n",
    "            for author in authors:\n",
    "                text = [filename for filename in files if author in filename if 'grc' in filename]\n",
    "                fileids += text\n",
    "    else:\n",
    "        for root, dirs, files in os.walk(path):\n",
    "            text = [filename for filename in files if 'grc' in filename]\n",
    "            fileids += text\n",
    "        \n",
    "            \n",
    "    # instantiate the reader with those files\n",
    "    reader = get_corpus_reader(corpus_name= 'greek_text_perseus', language='greek')\n",
    "    reader._fileids = fileids\n",
    "    \n",
    "    # use the reader to get a list of words (vocab) from the files\n",
    "    words = list(reader.words())\n",
    "    \n",
    "    # process the text, removing stopwords etc. \n",
    "    punct = \"!#$%&'()*+,-./:;<=>?@[\\]^_`{|}~᾽\"\n",
    "    swadesh = Swadesh('gr').words()\n",
    "    words = [word.lower() for word in words]\n",
    "    words = [word for word in words if word not in punct]\n",
    "    words = [word for word in words if word not in STOPS_LIST]\n",
    "    words_noswadesh = [word for word in words if word not in STOPS_LIST if not word in swadesh]\n",
    "    \n",
    "    # decide which output we want from the parameter 'swadesh'\n",
    "    if swadesh:\n",
    "        to_tag = words_noswadesh\n",
    "    else:\n",
    "        to_tag = words\n",
    "        \n",
    "    # instantiate POS tagger\n",
    "    tagger = POSTag('greek')\n",
    "    \n",
    "    # tag words using backoff tagger\n",
    "    joined = ' '.join(to_tag)\n",
    "    tagged = tagger.tag_ngram_123_backoff(joined)\n",
    "    \n",
    "    # create dataframe from tagged words\n",
    "    df = pd.DataFrame(tagged, columns=['word', 'pos'])\n",
    "    \n",
    "    # drop punctuation and useless words\n",
    "    df = df[(df.pos != 'U--------') & (df.pos != 'D--------')]\n",
    "    df.pos = df.pos.str.lower()\n",
    "    \n",
    "    # create separate dataframe containing the None's to compare later\n",
    "    nones = df[(df.pos.isnull() == True) & (df.word.isnull() != True)]\n",
    "    nones.drop_duplicates(ignore_index=True, inplace=True)\n",
    "    \n",
    "    # drop duplicates and nulls\n",
    "    df.dropna(inplace=True)\n",
    "    df.drop_duplicates(ignore_index=True, inplace=True)\n",
    "    \n",
    "    # return dataframe\n",
    "    return df, nones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mackmcgowen/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "df, nones = pull_data('/Users/mackmcgowen/cltk_data/greek/text/greek_text_perseus/cltk_json/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/corpus.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "nones.to_csv('../data/nones.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'δημήτηρ'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.word[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['δη', 'μή', 'τηρ']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syllabify(df.word[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['syllables'] = df.word.apply(lambda x: ' '.join(syllabify(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('../data/corpus.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.word.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "syll = list(map(lambda x: syllabify(x), test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['δη', 'μή', 'τηρ']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syll[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'δη μή τηρ'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(syll[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cltk.corpus.utils.importer import CorpusImporter\n",
    "from cltk.corpus.readers import get_corpus_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['greek_software_tlgu',\n",
       " 'greek_text_perseus',\n",
       " 'phi7',\n",
       " 'tlg',\n",
       " 'greek_proper_names_cltk',\n",
       " 'greek_models_cltk',\n",
       " 'greek_treebank_perseus',\n",
       " 'greek_treebank_gorman',\n",
       " 'greek_lexica_perseus',\n",
       " 'greek_training_set_sentence_cltk',\n",
       " 'greek_word2vec_cltk',\n",
       " 'greek_text_lacus_curtius',\n",
       " 'greek_text_first1kgreek',\n",
       " 'greek_text_tesserae']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CorpusImporter('greek').list_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CorpusImporter('greek').import_corpus('greek_treebank_perseus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Specified corpus data not found, please install greek_treebank_perseus for language: None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d8388b15c43f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_corpus_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_name\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'greek_treebank_perseus'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/cltk/corpus/readers.py\u001b[0m in \u001b[0;36mget_corpus_reader\u001b[0;34m(corpus_name, language)\u001b[0m\n\u001b[1;32m     47\u001b[0m         raise ValueError(\n\u001b[1;32m     48\u001b[0m             'Specified corpus data not found, please install {} for language: {}'.format(\n\u001b[0;32m---> 49\u001b[0;31m                 corpus_name, language))\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0msentence_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizeSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Specified corpus data not found, please install greek_treebank_perseus for language: None"
     ]
    }
   ],
   "source": [
    "reader = get_corpus_reader(corpus_name= 'greek_treebank_perseus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi] *",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
